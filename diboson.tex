%\begin{singlespace}
%\setstretch{1.25}
\begin{centering}
\chapter{Search I: First search for diboson resonances at 13 TeV}
\label{searchI}
\textit{
\noindent When the LHC started its Run II data taking period in summer 2015, it would be the first time ever for a particle collider to produce collisions with center-of-mass energies as high as 13 \TeV. The Higgs boson, for which the LHC was designed to observe, had been discovered at the end of the previous data taking era, leaving us with a Standard Model that we know is either in need of extensions or only an effective theory valid in a certain energy domain. The Run II search program would therefore be oriented around two main efforts: Precision measurements of the newly discovered Higgs boson and searches for physics beyond the standard model.
\newline
\newline
I started my PhD four months before the first 13 TeV collisions took place and had to consider the following:
What was the most interesting search that could be done on a short time scale (to be presented 6 months after first collisions, which would be at the CERN end-of-year "Jamboree"), whose physics objects could be reconstructed and understood on a relatively short time scale, and would be robust enough in case there were issues with the never-before-validated 13 \TeV Monte Carlo?
\newline
\newline
The attention of the high-energy physics community has in the past years been focused on certain "hot topics": In 2018 and currently in 2019, the excitement is over leptoquarks, which could explain anomalies observed by LHCb and b-factories; in 2016 and 2017 it was diphoton resonances, with $>3 \sigma$ excesses observed at the same mass in both CMS and ATLAS. And in 2015 during the 13 \TeV LHC start-up, attention was centered on diboson resonances in the all-hadronic final state. The choice was therefore clear: My first analysis would be a search for diboson resonances in the boosted dijet final state. With a background model based on a smooth fit to data in the signal region, eliminating the need for accurate QCD MC predictions, this was a simple one-background only (QCD) analysis, feasible to finalize in one year, given dedication and sufficient effort. Despite its straightforwardness, due to observed 8 TeV excesses, it was in addition considered a high-profile analysis.
\newline
\newline
This search became one of the first "boosted" searches published with data collected with a 13 TeV center-of-mass energy, as well as the first search to take advantage of dedicated "grooming" triggers. It was published with 2.7 \fbinv of 2015 data.
}
\end{centering}
\begin{flushright} \textit{- The author - } \end{flushright}
\begin{figure}[h!] 
    \centering
     \vspace*{10mm}
    \includegraphics[height=6.5cm]{figures/analysis/search1/misc/first_coll.png}
    \vspace*{10mm}
    \caption*{\footnotesize{\textit{Published in the Journal of High Energy Physics (2017), DOI: 10.1007/JHEP03(2017)162}}}
\end{figure}
%\end{singlespace}
\clearpage
\input{searchI.tex}
\clearpage

%\begin{singlespace}
%\setstretch{1.25}
\vspace*{\fill}
\begin{centering}
\chapter{Search II: A new pileup resistant and perturbative safe tagger}
\label{searchII}
\textit{
\noindent With the first diboson resonance search with a center-of-mass energy of 13 TeV published, we concluded that more data would be needed in order to fully exclude the excess observed in Run 1. Data from 2016 was right around the corner and, with the LHC planning to reduce $\beta^*$ from 80 to 40 \cm, the machine was expected to deliver an instantaneous luminosity three times that of the peak luminosity in 2015. This higher instantaneous luminosity, however, meant double the pileup.
\newline
\newline
We knew that a novel pileup-subtraction algorithm had been developed, which provided far better pileup rejection than the current default algorithm that used charged hadron subtraction. We also knew that there had been made progress on the theory side in the development of a groomer which was completely insensitive to correlated soft emissions (non-global logarithms), allowing jet grooming to be accomplished in a theoretically calculable way, softdrop with $\beta = 0$ (mMDT).
\newline
\newline
With more time at hand than in 2015, we therefore decided to pursue a novel W-tagger for this second search. This meant studying and optimizing new approaches for pileup rejection and grooming, developing dedicated jet-mass corrections, as well as validating this new tagger in MC and data. This tagger, together with the mass corrections, became the default and recommended W-tagging algorithm of CMS.
\newline
\newline
Search II was the first published analysis to use a novel combination of PUPPI and softdrop grooming algorithms, now default for W-tagging in CMS. Through this search, the tagger was optimized, commissioned and validated, making it available for several analysis to come. In addition, the search was extended to consider three additional signal hypothesis. Two of these were in a final state never before explored with a center-of-mass energy of 13 TeV, the excited quark scenario where $q^*$ decays to qW or qZ, and the vector boson is boosted and identified through V-tagging. It was published with 35.9 (12.9) \fbinv of 2016 data.
}
\end{centering}
\begin{flushright} \textit{- The author - } \end{flushright}
\begin{figure}[h!]
    \centering
     \vspace*{10mm}
    \includegraphics[height=6.5cm]{figures/vtagging/JME-16-003/BoostedW/WtagSigEffvsNPV.pdf}
    \vspace*{10mm}
    \caption*{\footnotesize{\textit{Published in PRD, DOI: 10.1103/PhysRevD.97.072006; CMS-PAS-B2G-16-021; CMS-PAS-JME-16-003}}}
\end{figure}
\vspace*{\fill}
%\end{singlespace}

\clearpage
\input{searchII.tex}
\clearpage

%\begin{singlespace}
%\setstretch{1.25}
\vspace*{\fill}
\begin{centering}
\chapter{Search III: A novel framework for multi-dimensional searches}
\label{searchIII}
\textit{
\noindent After two successful analysis using the LHC data collected at a center-of-mass energy of 13 TeV, there was no confirmation of the excess observed at a center-of-mass energy of 8 TeV, and the prospect of observing new physics in diboson analyses was bleak. However, this was not a source of concern to some theorists, who considered whether the small bumps that had been observed were due to us observing the tail of another type of boson with a mass slightly different from that of a W or a Z boson, and that perhaps these bosons were not 2-prong, but 4-prong objects.
\newline
\newline
With no significant excess observed with the 2016 dataset of 36 \fbinv, we were expecting to collect a total dataset of 150 \fbinv in Run 2 (2015-2018) that would allow us to probe alternative BSM models, and we wanted to do so as efficiently as possible. More specifically, we wanted a way of looking for any heavy resonance decaying to any two jets with substructure, with masses anywhere in the jet mass spectrum. We decided to do so by taking advantage of the fact that we are looking for bumps in a three-dimensional space: the mass of the two jets as well as their dijet invariant mass. The one-dimensional dijet fit can therefore be replaced by a three-dimensional fit, looking for bumps in all three dimensions simultaneously. This would allow us to easily search for resonances decaying to any object peaking in jet mass; W(qq), Z(qq), H(qq), as well as non-SM bosons; in one common framework.
\newline
\newline
An additional benefit of the method, was that the modeling of the QCD multijet background would start from simulation rather than relying on a parametric fit to data. This had the benefit of allowing more control over the background shape across the full dijet invariant mass spectrum, making the fit less prone to fluctuations in the low statistics tail of the distribution, something we found to be problematic with the 1D dijet fit method.
\newline
\newline
Search III introduces a novel three-dimensional fit method that can be used to search for heavy resonances decaying to any two jets with substructure peaking in the jet groomed mass spectrum. It is validated in the context of a diboson resonance search in the all-hadronic final state, but is easily extendable to other signals. The fit method has allowed for the first measurement of the jet mass scale and resolution simultaneously from a W(qq)+jets and Z(qq)+jets mass peak, and could also allow for the extraction of the SM W/Z+jets cross section. It was published with data collected in 2016 and 2017, corresponding to a total integrated luminosity of $\sim 80 \fbinv$.}
\end{centering}
 \begin{flushright} \textit{- The author - } \end{flushright}
\begin{figure}[h!]
    \centering
    \vspace*{10mm}
    \includegraphics[height=6.5cm]{figures/analysis/search3/B2G-18-002/PostFitComboHPLP_Y-Proj__x___0_-1_z___0_-1.pdf}
    \vspace*{10mm}
    \caption*{\footnotesize{\textit{In progress. To be submitted to The European Physical Journal C}}}
\end{figure}
%\end{singlespace}

\clearpage
\input{searchIII.tex}



